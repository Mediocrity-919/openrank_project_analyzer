import requests
import json
import os
import pandas as pd
import re
from concurrent.futures import ThreadPoolExecutor

class OpenDiggerURLFetcher:
    def __init__(self):
        self.metrics_list = [
            "openrank", "activity", "attention", "active_dates_and_times",
            "stars", "technical_fork", "participants", "new_contributors",
            "inactive_contributors", "bus_factor", "issues_new", "issues_closed",
            "issue_comments", "pr_new", "pr_merged", "pr_reviews",
            "merged_code_addition", "merged_code_deletion", "line_of_code_changed"
        ]

    def parse_github_url(self, url):
        """
        ä» GitHub ç½‘å€ä¸­æå– org å’Œ repo
        æ”¯æŒæ ¼å¼: 
        - https://github.com/org/repo
        - https://github.com/org/repo/tree/main
        - org/repo
        """
        url = url.strip()
        # å¤„ç†å®Œæ•´çš„ URL
        if "github.com/" in url:
            # ä½¿ç”¨æ­£åˆ™åŒ¹é…åŸŸååçš„å‰ä¸¤ä¸ªè·¯å¾„æ®µ
            match = re.search(r"github\.com/([^/]+)/([^/]+)", url)
            if match:
                org = match.group(1)
                repo = match.group(2).replace(".git", "") # å»æ‰å¯èƒ½å­˜åœ¨çš„ .git åç¼€
                return org, repo
        # å¤„ç†ç›´æ¥è¾“å…¥çš„ org/repo æ ¼å¼
        elif "/" in url:
            parts = url.split('/')
            return parts[0], parts[1]
        
        return None, None

    def fetch_single_metric(self, org, repo, metric):
        """è·å–å•ä¸ªæŒ‡æ ‡çš„ JSON å†…å®¹"""
        base_url = f"https://oss.open-digger.cn/github/{org}/{repo}/"
        url = f"{base_url}{metric}.json"
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                return metric, response.json()
        except:
            pass
        return metric, None

    def get_all_metrics(self, org, repo):
        """ä½¿ç”¨å¤šçº¿ç¨‹åŠ é€Ÿè·å–"""
        print(f"\nğŸš€ æ­£åœ¨ä¸ºä»“åº“ [{org}/{repo}] æ£€ç´¢ OpenDigger æŒ‡æ ‡...")
        results = {}
        with ThreadPoolExecutor(max_workers=10) as executor:
            # ä¼ é€’ org å’Œ repo å‚æ•°ç»™æŠ“å–å‡½æ•°
            task_results = list(executor.map(lambda m: self.fetch_single_metric(org, repo, m), self.metrics_list))
            
        for metric, data in task_results:
            if data:
                results[metric] = data
                print(f" âœ… {metric}")
        return results

    def export_data(self, org, repo, data):
        """ä¿å­˜ä¸º JSON å’Œ CSV"""
        if not data:
            print("âŒ æœªèƒ½è·å–åˆ°ä»»ä½•æœ‰æ•ˆæŒ‡æ ‡ã€‚")
            return

        # 1. ä¿å­˜åŸå§‹ JSON
        json_name = f"{org}_{repo}_raw.json"
        with open(json_name, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

        # 2. è½¬æ¢ä¸ºæœˆåº¦æ±‡æ€» CSV
        all_series = {}
        for metric, content in data.items():
            # ä»…ä¿ç•™ YYYY-MM æ ¼å¼çš„æœˆåº¦æ•°æ®
            monthly_values = {k: v for k, v in content.items() if re.match(r'^\d{4}-\d{2}$', str(k))}
            if monthly_values:
                all_series[metric] = pd.Series(monthly_values)
        
        if all_series:
            df = pd.DataFrame(all_series).sort_index()
            csv_name = f"{org}_{repo}_summary.csv"
            df.to_csv(csv_name, encoding='utf-8-sig')
            print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜ï¼š\n - åŸå§‹æ•°æ®: {json_name}\n - æ±‡æ€»æŠ¥è¡¨: {csv_name}")
            print("\n--- æœ€è¿‘ 3 ä¸ªæœˆæ•°æ®é¢„è§ˆ ---")
            print(df.tail(3))

def main():
    fetcher = OpenDiggerURLFetcher()
    user_input = input("è¯·è¾“å…¥ GitHub é¡¹ç›®ç½‘å€ (ä¾‹å¦‚ https://github.com/pingcap/tidb): ")
    
    org, repo = fetcher.parse_github_url(user_input)
    
    if org and repo:
        full_data = fetcher.get_all_metrics(org, repo)
        fetcher.export_data(org, repo, full_data)
    else:
        print("âŒ æ— æ³•è§£æç½‘å€ã€‚è¯·ç¡®ä¿è¾“å…¥æ­£ç¡®çš„ GitHub åœ°å€ï¼Œå¦‚ https://github.com/ç»„ç»‡/ä»“åº“")

if __name__ == "__main__":
    main()